{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a4464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U transformers datasets evaluate accelerate torch\n",
    "# %pip uninstall -y torch torchvision torchaudio\n",
    "# %pip cache purge\n",
    "# %pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81731e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import platform\n",
    "import socket\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c00b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Helpers ----------\n",
    "def run(cmd):\n",
    "    return subprocess.check_output(cmd, text=True).strip()\n",
    "\n",
    "def get_imds_token(timeout=2):\n",
    "    \"\"\"Get IMDSv2 token (works when IMDS is enabled; required on many EC2 configs).\"\"\"\n",
    "    try:\n",
    "        r = requests.put(\n",
    "            \"http://169.254.169.254/latest/api/token\",\n",
    "            headers={\"X-aws-ec2-metadata-token-ttl-seconds\": \"21600\"},\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        if r.status_code == 200:\n",
    "            return r.text\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def get_imds(path, token=None, timeout=2):\n",
    "    \"\"\"Query EC2 instance metadata. Returns None if not on EC2 / blocked.\"\"\"\n",
    "    url = f\"http://169.254.169.254/latest/meta-data/{path}\"\n",
    "    headers = {}\n",
    "    if token:\n",
    "        headers[\"X-aws-ec2-metadata-token\"] = token\n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, timeout=timeout)\n",
    "        if r.status_code == 200:\n",
    "            return r.text\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d204db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EC2 Proof ===\n",
      "hostname: kathy_arz\n",
      "local time: 2026-02-03T20:57:30\n",
      "instance-id: None\n",
      "instance-type: None\n",
      "availability-zone: None\n",
      "WARNING: Could not access EC2 metadata. You might not be on EC2, or IMDS is disabled/blocked.\n",
      "\n",
      "=== System ===\n",
      "platform: Windows-10-10.0.26200-SP0\n"
     ]
    }
   ],
   "source": [
    "token = get_imds_token()\n",
    "instance_id = get_imds(\"instance-id\", token)\n",
    "instance_type = get_imds(\"instance-type\", token)\n",
    "az = get_imds(\"placement/availability-zone\", token)\n",
    "\n",
    "print(\"=== EC2 Proof ===\")\n",
    "print(\"hostname:\", socket.gethostname())\n",
    "print(\"local time:\", datetime.now().isoformat(timespec=\"seconds\"))\n",
    "print(\"instance-id:\", instance_id)\n",
    "print(\"instance-type:\", instance_type)\n",
    "print(\"availability-zone:\", az)\n",
    "\n",
    "if instance_id is None:\n",
    "    print(\"WARNING: Could not access EC2 metadata. You might not be on EC2, or IMDS is disabled/blocked.\")\n",
    "else:\n",
    "    print(\"OK: EC2 metadata accessible (strong proof you're on an EC2 instance).\")\n",
    "\n",
    "# Optional extra evidence: show OS + kernel\n",
    "print(\"\\n=== System ===\")\n",
    "print(\"platform:\", platform.platform())\n",
    "try:\n",
    "    print(\"uname -a:\", run([\"uname\", \"-a\"]))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d5298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Python & Packages ===\n",
      "python: 3.11.11\n",
      "torch: 2.10.0+cpu\n",
      "transformers: 5.0.0\n",
      "requests: 2.32.3\n",
      "cuda available: False\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Python & Packages ===\")\n",
    "print(\"python:\", platform.python_version())\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"transformers:\", __import__(\"transformers\").__version__)\n",
    "print(\"requests:\", requests.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda version:\", torch.version.cuda)\n",
    "    print(\"gpu name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5aee63e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'BertModel'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2098\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2098\u001b[39m     module = \u001b[38;5;28mself\u001b[39m._get_module(\u001b[38;5;28mself\u001b[39m._class_to_module[name])\n\u001b[32m   2099\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2288\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2286\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2285\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m + module_name, \u001b[38;5;28mself\u001b[39m.\u001b[34m__name__\u001b[39m)\n\u001b[32m   2287\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\importlib\\__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap._gcd_import(name[level:], package, level)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:29\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmasking_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_bidirectional_mask, create_causal_mask\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_layers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradientCheckpointingLayer\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     31\u001b[39m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[32m     32\u001b[39m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     TokenClassifierOutput,\n\u001b[32m     40\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\modeling_layers.py:27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocessing_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Unpack\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformersKwargs, auto_docstring, can_return_tuple, logging\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\processing_utils.py:38\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchFeature\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChannelDimension, ImageInput, is_vision_available\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtokenization_utils_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     40\u001b[39m     PaddingStrategy,\n\u001b[32m     41\u001b[39m     PreTokenizedInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     TruncationStrategy,\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\image_utils.py:53\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torchvision_available():\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n\u001b[32m     55\u001b[39m     pil_torch_interpolation_mapping = {\n\u001b[32m     56\u001b[39m         PILImageResampling.NEAREST: InterpolationMode.NEAREST_EXACT,\n\u001b[32m     57\u001b[39m         PILImageResampling.BOX: InterpolationMode.BOX,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m         PILImageResampling.LANCZOS: InterpolationMode.LANCZOS,\n\u001b[32m     62\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grad.new_empty((batch_size, channels, height, width))\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;129m@torch\u001b[39m.library.register_fake(\u001b[33m\"\u001b[39m\u001b[33mtorchvision::nms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmeta_nms\u001b[39m(dets, scores, iou_threshold):\n\u001b[32m    165\u001b[39m     torch._check(dets.dim() == \u001b[32m2\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mboxes should be a 2d tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\torch\\library.py:1073\u001b[39m, in \u001b[36mregister\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mregister_autograd\u001b[39m(\n\u001b[32m   1034\u001b[39m     op: _op_identifier,\n\u001b[32m   1035\u001b[39m     backward: Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1039\u001b[39m     lib=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1040\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1041\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Register a backward formula for this custom op.\u001b[39;00m\n\u001b[32m   1042\u001b[39m \n\u001b[32m   1043\u001b[39m \u001b[33;03m    In order for an operator to work with autograd, you need to register\u001b[39;00m\n\u001b[32m   1044\u001b[39m \u001b[33;03m    a backward formula:\u001b[39;00m\n\u001b[32m   1045\u001b[39m \u001b[33;03m    1. You must tell us how to compute gradients during the backward pass\u001b[39;00m\n\u001b[32m   1046\u001b[39m \u001b[33;03m    by providing us a \"backward\" function.\u001b[39;00m\n\u001b[32m   1047\u001b[39m \u001b[33;03m    2. If you need any values from the forward to compute gradients, you can\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03m    use `setup_context` to save values for backward.\u001b[39;00m\n\u001b[32m   1049\u001b[39m \n\u001b[32m   1050\u001b[39m \u001b[33;03m    ``backward`` runs during the backward pass. It accepts ``(ctx, *grads)``:\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[33;03m    - ``grads`` is one or more gradients. The number of gradients matches\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[33;03m    the number of outputs of the operator.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[33;03m    The ``ctx`` object is `the same ctx object <context_method_mixins>`_ used by\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[33;03m    :class:`torch.autograd.Function`. The semantics of ``backward_fn`` are the\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    same as :meth:`torch.autograd.Function.backward`.\u001b[39;00m\n\u001b[32m   1056\u001b[39m \n\u001b[32m   1057\u001b[39m \u001b[33;03m    ``setup_context(ctx, inputs, output)`` runs during the forward pass.\u001b[39;00m\n\u001b[32m   1058\u001b[39m \u001b[33;03m    Please save quantities needed for backward onto the ``ctx`` object via\u001b[39;00m\n\u001b[32m   1059\u001b[39m \u001b[33;03m    either :meth:`torch.autograd.function.FunctionCtx.save_for_backward`\u001b[39;00m\n\u001b[32m   1060\u001b[39m \u001b[33;03m    or assigning them as attributes of ``ctx``. If your custom op has\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[33;03m    kwarg-only arguments, we expect the signature of ``setup_context``\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[33;03m    to be ``setup_context(ctx, inputs, keyword_only_inputs, output)``.\u001b[39;00m\n\u001b[32m   1063\u001b[39m \n\u001b[32m   1064\u001b[39m \u001b[33;03m    Both ``setup_context_fn`` and ``backward_fn`` must be traceable. That is,\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[33;03m    they may not directly access :meth:`torch.Tensor.data_ptr` and they must\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[33;03m    not depend on or mutate global state. If you need a non-traceable backward,\u001b[39;00m\n\u001b[32m   1067\u001b[39m \u001b[33;03m    you can make it a separate custom_op that you call inside ``backward_fn``.\u001b[39;00m\n\u001b[32m   1068\u001b[39m \n\u001b[32m   1069\u001b[39m \u001b[33;03m    If you need different autograd behavior on different devices, then we\u001b[39;00m\n\u001b[32m   1070\u001b[39m \u001b[33;03m    recommend creating two different custom operators, one for each device\u001b[39;00m\n\u001b[32m   1071\u001b[39m \u001b[33;03m    that needs different behavior, and switching between them at runtime.\u001b[39;00m\n\u001b[32m   1072\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1073\u001b[39m \u001b[33;03m    Examples:\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m        >>> import torch\u001b[39;00m\n\u001b[32m   1075\u001b[39m \u001b[33;03m        >>> import numpy as np\u001b[39;00m\n\u001b[32m   1076\u001b[39m \u001b[33;03m        >>> from torch import Tensor\u001b[39;00m\n\u001b[32m   1077\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1078\u001b[39m \u001b[33;03m        >>> @torch.library.custom_op(\"mylib::numpy_sin\", mutates_args=())\u001b[39;00m\n\u001b[32m   1079\u001b[39m \u001b[33;03m        >>> def numpy_sin(x: Tensor) -> Tensor:\u001b[39;00m\n\u001b[32m   1080\u001b[39m \u001b[33;03m        >>>     x_np = x.cpu().numpy()\u001b[39;00m\n\u001b[32m   1081\u001b[39m \u001b[33;03m        >>>     y_np = np.sin(x_np)\u001b[39;00m\n\u001b[32m   1082\u001b[39m \u001b[33;03m        >>>     return torch.from_numpy(y_np).to(device=x.device)\u001b[39;00m\n\u001b[32m   1083\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1084\u001b[39m \u001b[33;03m        >>> def setup_context(ctx, inputs, output) -> Tensor:\u001b[39;00m\n\u001b[32m   1085\u001b[39m \u001b[33;03m        >>>     x, = inputs\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m        >>>     ctx.save_for_backward(x)\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1088\u001b[39m \u001b[33;03m        >>> def backward(ctx, grad):\u001b[39;00m\n\u001b[32m   1089\u001b[39m \u001b[33;03m        >>>     x, = ctx.saved_tensors\u001b[39;00m\n\u001b[32m   1090\u001b[39m \u001b[33;03m        >>>     return grad * x.cos()\u001b[39;00m\n\u001b[32m   1091\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[33;03m        >>> torch.library.register_autograd(\u001b[39;00m\n\u001b[32m   1093\u001b[39m \u001b[33;03m        ...     \"mylib::numpy_sin\", backward, setup_context=setup_context\u001b[39;00m\n\u001b[32m   1094\u001b[39m \u001b[33;03m        ... )\u001b[39;00m\n\u001b[32m   1095\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[33;03m        >>> x = torch.randn(3, requires_grad=True)\u001b[39;00m\n\u001b[32m   1097\u001b[39m \u001b[33;03m        >>> y = numpy_sin(x)\u001b[39;00m\n\u001b[32m   1098\u001b[39m \u001b[33;03m        >>> (grad_x,) = torch.autograd.grad(y, x, torch.ones_like(y))\u001b[39;00m\n\u001b[32m   1099\u001b[39m \u001b[33;03m        >>> assert torch.allclose(grad_x, x.cos())\u001b[39;00m\n\u001b[32m   1100\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1101\u001b[39m \u001b[33;03m        >>> # Example with a keyword-only arg\u001b[39;00m\n\u001b[32m   1102\u001b[39m \u001b[33;03m        >>> @torch.library.custom_op(\"mylib::numpy_mul\", mutates_args=())\u001b[39;00m\n\u001b[32m   1103\u001b[39m \u001b[33;03m        >>> def numpy_mul(x: Tensor, *, val: float) -> Tensor:\u001b[39;00m\n\u001b[32m   1104\u001b[39m \u001b[33;03m        >>>     x_np = x.cpu().numpy()\u001b[39;00m\n\u001b[32m   1105\u001b[39m \u001b[33;03m        >>>     y_np = x_np * val\u001b[39;00m\n\u001b[32m   1106\u001b[39m \u001b[33;03m        >>>     return torch.from_numpy(y_np).to(device=x.device)\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1108\u001b[39m \u001b[33;03m        >>> def setup_context(ctx, inputs, keyword_only_inputs, output) -> Tensor:\u001b[39;00m\n\u001b[32m   1109\u001b[39m \u001b[33;03m        >>>     ctx.val = keyword_only_inputs[\"val\"]\u001b[39;00m\n\u001b[32m   1110\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1111\u001b[39m \u001b[33;03m        >>> def backward(ctx, grad):\u001b[39;00m\n\u001b[32m   1112\u001b[39m \u001b[33;03m        >>>     return grad * ctx.val\u001b[39;00m\n\u001b[32m   1113\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1114\u001b[39m \u001b[33;03m        >>> torch.library.register_autograd(\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[33;03m        ...     \"mylib::numpy_mul\", backward, setup_context=setup_context\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[33;03m        ... )\u001b[39;00m\n\u001b[32m   1117\u001b[39m \u001b[33;03m        >>>\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[33;03m        >>> x = torch.randn(3, requires_grad=True)\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[33;03m        >>> y = numpy_mul(x, val=3.14)\u001b[39;00m\n\u001b[32m   1120\u001b[39m \u001b[33;03m        >>> (grad_x,) = torch.autograd.grad(y, x, torch.ones_like(y))\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[33;03m        >>> assert torch.allclose(grad_x, torch.full_like(x, 3.14))\u001b[39;00m\n\u001b[32m   1122\u001b[39m \n\u001b[32m   1123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   1124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1125\u001b[39m         op, (\u001b[38;5;28mstr\u001b[39m, torch._ops.OpOverload, torch._library.custom_ops.CustomOpDef)\n\u001b[32m   1126\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\torch\\library.py:203\u001b[39m, in \u001b[36m_register_fake\u001b[39m\u001b[34m(self, op_name, fn, _stacklevel, allow_override)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;66;03m# TODO(rzou): We're gonna need to stage this change with torchvision,\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;66;03m# since torchvision is github first.\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m caller_module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m caller_module_name.startswith(\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorchvision.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m ):\n\u001b[32m    205\u001b[39m     caller_module_name = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\torch\\_library\\fake_impl.py:50\u001b[39m, in \u001b[36mregister\u001b[39m\u001b[34m(self, func, source, lib, allow_override)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._C._dispatch_has_kernel_for_dispatch_key(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.qualname, \u001b[33m\"\u001b[39m\u001b[33mCompositeImplicitAutograd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m ):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     44\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an implementation for this device type via a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpre-existing registration to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDispatchKey::CompositeImplicitAutograd.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCompositeImplicitAutograd operators do not need an fake \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mimpl; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minstead, the operator will decompose into its constituents \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mand those \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcan have fake impls defined on them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m     )\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Store the kernel in this holder\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: operator torchvision::nms does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mHello from EC2. This is a BERT smoke test.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m tokenizer = AutoTokenizer.from_pretrained(ckpt)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = AutoModel.from_pretrained(ckpt)\n\u001b[32m      8\u001b[39m inputs = tokenizer(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:369\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class.from_pretrained(\n\u001b[32m    366\u001b[39m         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n\u001b[32m    367\u001b[39m     )\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    371\u001b[39m         config = config.get_text_config()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:178\u001b[39m, in \u001b[36m_get_model_class\u001b[39m\u001b[34m(config, model_mapping)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     supported_models = model_mapping[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    180\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:570\u001b[39m, in \u001b[36m_LazyAutoMapping.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    568\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._model_mapping:\n\u001b[32m    569\u001b[39m     model_name = \u001b[38;5;28mself\u001b[39m._model_mapping[model_type]\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._load_attr_from_module(model_type, model_name)\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[32m    573\u001b[39m model_types = [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_mapping.items() \u001b[38;5;28;01mif\u001b[39;00m v == key.\u001b[34m__name__\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:584\u001b[39m, in \u001b[36m_LazyAutoMapping._load_attr_from_module\u001b[39m\u001b[34m(self, model_type, attr)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m    583\u001b[39m     \u001b[38;5;28mself\u001b[39m._modules[module_name] = importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransformers.models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(\u001b[38;5;28mself\u001b[39m._modules[module_name], attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:496\u001b[39m, in \u001b[36mgetattribute_from_module\u001b[39m\u001b[34m(module, attr)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, attr):\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[32m    498\u001b[39m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\0-Kathy Cui\\0-Northwestern\\0-Classes\\3rd Year\\Spring 2025\\CS352\\.conda\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2182\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2178\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2179\u001b[39m                         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2180\u001b[39m                     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2181\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2182\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2183\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2184\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2186\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m   2187\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Could not import module 'BertModel'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "# ---------- BERT Smoke Test ----------\n",
    "ckpt = \"bert-base-uncased\"\n",
    "text = \"Hello from EC2. This is a BERT smoke test.\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "model = AutoModel.from_pretrained(ckpt)\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# CLS embedding (standard for sentence embedding demo)\n",
    "cls = outputs.last_hidden_state[:, 0, :]\n",
    "print(\"CLS embedding shape:\", cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13789ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ckpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m out_dir = \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m os.makedirs(out_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m payload = {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m: datetime.now().isoformat(timespec=\u001b[33m\"\u001b[39m\u001b[33mseconds\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhostname\u001b[39m\u001b[33m\"\u001b[39m: socket.gethostname(),\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstance_id\u001b[39m\u001b[33m\"\u001b[39m: instance_id,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstance_type\u001b[39m\u001b[33m\"\u001b[39m: instance_type,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mavailability_zone\u001b[39m\u001b[33m\"\u001b[39m: az,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m: platform.python_version(),\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m: torch.__version__,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28m__import__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m).__version__,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcuda_available\u001b[39m\u001b[33m\"\u001b[39m: torch.cuda.is_available(),\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheckpoint\u001b[39m\u001b[33m\"\u001b[39m: ckpt,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcls_embedding_shape\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mcls\u001b[39m.shape),\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcls_embedding_first5\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mcls\u001b[39m[\u001b[32m0\u001b[39m, :\u001b[32m5\u001b[39m].tolist(),\n\u001b[32m     18\u001b[39m }\n\u001b[32m     20\u001b[39m path = os.path.join(out_dir, \u001b[33m\"\u001b[39m\u001b[33mec2_bert_smoketest.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'ckpt' is not defined"
     ]
    }
   ],
   "source": [
    "out_dir = \"outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "payload = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"hostname\": socket.gethostname(),\n",
    "    \"instance_id\": instance_id,\n",
    "    \"instance_type\": instance_type,\n",
    "    \"availability_zone\": az,\n",
    "    \"python\": platform.python_version(),\n",
    "    \"torch\": torch.__version__,\n",
    "    \"transformers\": __import__(\"transformers\").__version__,\n",
    "    \"cuda_available\": torch.cuda.is_available(),\n",
    "    \"checkpoint\": ckpt,\n",
    "    \"text\": text,\n",
    "    \"cls_embedding_shape\": list(cls.shape),\n",
    "    \"cls_embedding_first5\": cls[0, :5].tolist(),\n",
    "}\n",
    "\n",
    "path = os.path.join(out_dir, \"ec2_bert_smoketest.json\")\n",
    "with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved proof file:\", path)\n",
    "print(\"Done âœ…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
